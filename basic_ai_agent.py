# -*- coding: utf-8 -*-
"""Basic_AI_Agent.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bf2VGhHsUQHBzb9kXfc7yFKs_ILVQ1q-
"""

!pip install llama-index
!pip install llama-index-llms-groq
!pip install llama-index-embeddings-huggingface

# Setup Groq LLM connection
from llama_index.llms.groq import Groq
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core import Settings
import os
import nest_asyncio

nest_asyncio.apply()

# Get Groq API key from Colab secrets
from google.colab import userdata
groq_api_key = userdata.get('GROQ_API_KEY')

# Setup the LLM with Groq
Settings.llm = Groq(
    model="meta-llama/llama-4-scout-17b-16e-instruct",  # You can also use "llama2-70b-4096" or other available models
    api_key=groq_api_key,
)

# Setup the embedding model with SentenceTransformers
Settings.embed_model = HuggingFaceEmbedding(
    model_name="sentence-transformers/all-MiniLM-L6-v2"  # Lightweight and efficient model
)

# Create indexes for vector search
from llama_index.core import SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core import VectorStoreIndex

splitter = SentenceSplitter(chunk_size=1024)

#-------------------------------------------------------------------
# Setup Aeroflow document index
#-------------------------------------------------------------------
aeroflow_documents = SimpleDirectoryReader(
    input_files=["AeroFlow_Specification_Document.pdf"]
).load_data()

# Read documents into nodes
aeroflow_nodes = splitter.get_nodes_from_documents(aeroflow_documents)
# Create a vector Store
aeroflow_index = VectorStoreIndex(aeroflow_nodes)
# Create a query engine
aeroflow_query_engine = aeroflow_index.as_query_engine()

#-------------------------------------------------------------------
# Setup EchoSprint document index
#-------------------------------------------------------------------
ecosprint_documents = SimpleDirectoryReader(
    input_files=["EcoSprint_Specification_Document.pdf"]
).load_data()
# Read documents into nodes
ecosprint_nodes = splitter.get_nodes_from_documents(ecosprint_documents)
# Create a vector Store
ecosprint_index = VectorStoreIndex(ecosprint_nodes)
# Create a query engine
ecosprint_query_engine = ecosprint_index.as_query_engine()

from llama_index.core.tools import QueryEngineTool
from llama_index.core.query_engine.router_query_engine import RouterQueryEngine
from llama_index.core.selectors import LLMSingleSelector

# Create a query engine Tool for AeroFlow
aeroflow_tool = QueryEngineTool.from_defaults(
    query_engine=aeroflow_query_engine,
    name="Aeroflow specifications",
    description=(
        "Contains information about Aeroflow : Design, features, technology, maintenance, warranty"
    ),
)

# Create a query engine Tool for EcoSprint
ecosprint_tool = QueryEngineTool.from_defaults(
    query_engine=ecosprint_query_engine,
    name="EcoSprint specifications",
    description=(
        "Contains information about EcoSprint : Design, features, technology, maintenance, warranty"
    ),
)

# Create a Router Agent. Provide the Tools to the Agent
router_agent = RouterQueryEngine(
    selector=LLMSingleSelector.from_defaults(),
    query_engine_tools=[
        aeroflow_tool,
        ecosprint_tool,
    ],
    verbose=True
)

# Ask questions
response = router_agent.query("What colors are available for AeroFlow?")
print("\nResponse: ", str(response))

response = router_agent.query("What colors are available for EcoSprint?")
print("\nResponse: ", str(response))

# response = router_agent.query("What are design specifications?")
# print("\nResponse: ", str(response))

